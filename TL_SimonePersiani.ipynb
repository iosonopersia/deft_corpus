{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oBXU9TA8gI8"
      },
      "source": [
        "# Tesi di laurea di Simone Persiani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yixU8h1741gD"
      },
      "source": [
        "## Imports and constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zNMEyiE_43Y3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2TdlQ9u47lv"
      },
      "source": [
        "Imports from PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UHFL-ZMx47Cy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.nn import BCELoss, Module, Linear, Dropout\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "#from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.utils.data.sampler import WeightedRandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPptBT4PKdoh"
      },
      "source": [
        "Constants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bQx0Z0Kfhl",
        "outputId": "0b768a34-2ebd-4dfc-d98d-5c6c4886698a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda.\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}.\")\n",
        "\n",
        "EMBEDDINGS_SIZE = 768 # or 1024 for roberta_large\n",
        "MODEL_SAVE_PATH = \"./model_augmented.pt\"\n",
        "RANDOM_SEED = 42\n",
        "DATASET = \"augmented\"  # \"preprocessed\" | \"augmented\"\n",
        "\n",
        "config = {\n",
        "  \"learning_rate\": 1e-5,\n",
        "  \"epochs\": 4,\n",
        "  \"hidden_layer_size\": 128,\n",
        "  \"batch_size\": 16,\n",
        "  \"weight_decay\": 0.01,  # NEW\n",
        "  \"label_smoothing\": 0.1,  # NEW\n",
        "  \"dataset\": DATASET\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck_M4QzaHjCD"
      },
      "source": [
        "Setting random seeds to obtain a deterministic behaviour:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w1yu2ym7HoEG"
      },
      "outputs": [],
      "source": [
        "def random_state(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "random_state(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uERRbKGxzCDD"
      },
      "source": [
        "## Download RoBERTa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQl6KLAta25F"
      },
      "source": [
        "Download the model and the tokenizer.\n",
        "\n",
        "[This work](https://github.com/avramandrei/UPB-SemEval-2020-Task-6) showed that a fine-tuned RoBERTa model is the best-performing variant of BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue_YKPCOaS7c",
        "outputId": "965158cf-726e-4eeb-ec29-d1378f5a5218"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "\n",
        "roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_tokenizer.add_tokens([\"<link>\", \"<equation>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWQuxzzA4MDM"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f5GngRPp2mcH"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_path, tokenizer):\n",
        "  df = pd.read_csv(dataset_path, sep=\"\\t\", header=0, encoding='utf-8',\n",
        "                   names=[\"SENTENCE\", \"HAS_DEF\"], usecols=[\"SENTENCE\", \"HAS_DEF\"],\n",
        "                   dtype={\"SENTENCE\": str, \"HAS_DEF\": np.uint8})\n",
        "\n",
        "  X, y = df[\"SENTENCE\"].tolist(), df[\"HAS_DEF\"].tolist()\n",
        "\n",
        "  encodings = tokenizer(X, add_special_tokens=True, max_length=60,\n",
        "                        padding=\"longest\", truncation=\"longest_first\",\n",
        "                        return_attention_mask=True, return_tensors=\"pt\")\n",
        "\n",
        "  X = encodings['input_ids'].to(dtype=torch.int32, device='cpu')\n",
        "  y = torch.tensor(y, dtype=torch.int64, device='cpu')\n",
        "  mask = encodings['attention_mask'].to(dtype=torch.uint8, device='cpu')\n",
        "\n",
        "  dataset = TensorDataset(X, y, mask)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "train_ds = load_dataset(f'./dataset/{DATASET}/train.tsv', roberta_tokenizer)\n",
        "val_ds   = load_dataset(f'./dataset/{DATASET}/dev.tsv',   roberta_tokenizer)\n",
        "test_ds  = load_dataset(f'./dataset/preprocessed/test.tsv',  roberta_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVxJb5rMBmOf"
      },
      "source": [
        "Preparing a WeightedRandomSampler so that training batches will contain, _on average_, the same amount of positive and negative samples.\n",
        "\n",
        "**This should address the problem of the unbalanced DEFT dataset. In general, one would expect definitions to be a relatively-rare occurrence in a Natural Language text.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G23hMg9GODbE",
        "outputId": "44a63532-67f5-4096-b330-24dc5f242ed8"
      },
      "outputs": [],
      "source": [
        "def buildWeightedSampler(dataset):  # NEW\n",
        "    labels = dataset.tensors[1]  # {0: X, 1: y, 2: mask}\n",
        "\n",
        "    n_samples = labels.shape[0]\n",
        "    def_samples = torch.sum(labels).item()\n",
        "\n",
        "    non_def_samples = n_samples - def_samples\n",
        "\n",
        "    class_weights = {0: n_samples / non_def_samples,\n",
        "                    1: n_samples / def_samples}\n",
        "    print(f\"Sampler weights: {class_weights}\")\n",
        "\n",
        "    sample_weights = torch.tensor([class_weights[label.item()] for label in labels], dtype=torch.double, device='cpu')\n",
        "    weighted_sampler = WeightedRandomSampler(weights=sample_weights,\n",
        "                                            num_samples=n_samples,\n",
        "                                            replacement=True)\n",
        "    # Param replacement=True means that the same sample can be selected more than once inside a single batch!\n",
        "    \n",
        "    return weighted_sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nc1OpdGdKRFI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampler weights: {0: 1.4560756501182033, 1: 3.1926187020526644}\n"
          ]
        }
      ],
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(RANDOM_SEED)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=config[\"batch_size\"], sampler=buildWeightedSampler(train_ds),\n",
        "                          worker_init_fn=seed_worker, generator=g)  # We want a reproducible behaviour in the order of data loading\n",
        "val_loader = DataLoader(dataset=val_ds, batch_size=config[\"batch_size\"], sampler=SequentialSampler(val_ds))\n",
        "test_loader = DataLoader(dataset=test_ds, batch_size=config[\"batch_size\"], sampler=SequentialSampler(test_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smooth_labels(labels, smoothing = 0.0):\n",
        "    assert 0 <= smoothing < 1\n",
        "\n",
        "    confidence = 1.0 - smoothing\n",
        "    uniform_probability = 0.5\n",
        "\n",
        "    smoothed_true_label = confidence + smoothing * uniform_probability\n",
        "    smoothed_false_label = smoothing * uniform_probability\n",
        "\n",
        "    smoothed_labels = torch.tensor([smoothed_true_label if v == 1 else smoothed_false_label for v in labels], dtype=torch.float, device=DEVICE, requires_grad=False)\n",
        "\n",
        "    return smoothed_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy2FSIIwKRe8"
      },
      "source": [
        "## Prepare the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_sNSYhNzGj9"
      },
      "source": [
        "### Define the classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NAQxZB6OzKkl"
      },
      "outputs": [],
      "source": [
        "class RoBERTaWithMLP(Module):\n",
        "  \"\"\" See: https://github.com/avramandrei/UPB-SemEval-2020-Task-6/blob/77d92e9c386f270af6ed1db259d3ba6e8bde307b/task1/model.py#L49-L80 \"\"\"\n",
        "  \n",
        "  def __init__(self, lang_model, vocab_size, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.lang_model = lang_model\n",
        "    self.lang_model.resize_token_embeddings(vocab_size)\n",
        "\n",
        "    self.linear1 = Linear(input_size, hidden_size)\n",
        "    self.dropout1 = Dropout(0.8)\n",
        "    self.linear2 = Linear(hidden_size, hidden_size)\n",
        "    self.dropout2 = Dropout(0.8)\n",
        "    self.linear3 = Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    embeddings = self.lang_model(x, attention_mask=mask)[0]\n",
        "    embeddings = torch.mean(embeddings, dim=1)\n",
        "\n",
        "    output = self.dropout1(F.gelu(self.linear1(embeddings)))\n",
        "    output = self.dropout2(F.gelu(self.linear2(output)))\n",
        "    output = torch.sigmoid(self.linear3(output))\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SR48nBa0Bfs"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4W0v_mxDS1a"
      },
      "source": [
        "The training dataloader uses the weighted sampler instead of simply shuffling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, criterion):\n",
        "  loss, acc, f1 = (0,) * 3\n",
        "  with torch.no_grad():\n",
        "    for (val_x, val_y, mask) in val_loader:\n",
        "      # Move data to the device in use\n",
        "      val_x = val_x.to(DEVICE)\n",
        "      val_y = val_y.to(DEVICE)\n",
        "      mask = mask.to(DEVICE)\n",
        "\n",
        "      # Forward pass\n",
        "      output = model.forward(val_x, mask)\n",
        "      output = torch.reshape(output, (-1,))\n",
        "\n",
        "      smoothed_labels = smooth_labels(val_y, config['label_smoothing'])\n",
        "      curr_loss = criterion(output, smoothed_labels)\n",
        "\n",
        "      # Performance evaluation\n",
        "      pred = torch.tensor([0 if x < 0.5 else 1 for x in output])\n",
        "      curr_acc = accuracy_score(val_y.cpu(), pred.cpu()) * 100.0\n",
        "      # curr_prec = precision_score(val_y.cpu(), pred.cpu()) * 100.0\n",
        "      # curr_rec = recall_score(val_y.cpu(), pred.cpu()) * 100.0\n",
        "      # curr_f1 = f1_score(val_y.cpu(), pred.cpu()) * 100.0\n",
        "\n",
        "      loss += float(curr_loss.item())\n",
        "      acc += float(curr_acc)\n",
        "      #f1 += float(curr_f1)\n",
        "      # prec += curr_prec\n",
        "      # rec += curr_rec\n",
        "      \n",
        "    loss /= len(val_loader)\n",
        "    acc /= len(val_loader)\n",
        "    # f1 /= len(val_loader)\n",
        "    # prec /= len(val_loader)\n",
        "    # rec /= len(val_loader)\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcxtUQ8a0DEv",
        "outputId": "5b7800b9-0f90-48a3-83c5-94c1aacaf695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'batch': 1, 'train/loss': 0.7065033912658691, 'train/accuracy': 37.5}\n",
            "{'epoch': 1, 'batch': 501, 'train/loss': 0.6547402101838422, 'train/accuracy': 62.899201596806385}\n",
            "{'epoch': 1, 'batch': 1001, 'train/loss': 0.6076706166748519, 'train/accuracy': 70.29845154845155}\n",
            "{'epoch': 1, 'batch': 1501, 'train/loss': 0.5802838175515982, 'train/accuracy': 73.72584943371086}\n",
            "{'epoch': 1, 'validation/loss': 0.4440178293915628, 'validation/accuracy': 84.22330097087378}\n",
            "Accuracy score improved from 0 -> 84.2233. Saving model... DONE!\n",
            "{'epoch': 2, 'batch': 1, 'train/loss': 0.5744534134864807, 'train/accuracy': 75.0}\n",
            "{'epoch': 2, 'batch': 501, 'train/loss': 0.4718650896511154, 'train/accuracy': 85.60379241516966}\n",
            "{'epoch': 2, 'batch': 1001, 'train/loss': 0.4653970293112687, 'train/accuracy': 85.91408591408592}\n",
            "{'epoch': 2, 'batch': 1501, 'train/loss': 0.4562308674927635, 'train/accuracy': 86.58394403730846}\n",
            "{'epoch': 2, 'validation/loss': 0.4355101359700694, 'validation/accuracy': 85.25485436893204}\n",
            "Accuracy score improved from 84.2233 -> 85.2549. Saving model... DONE!\n",
            "{'epoch': 3, 'batch': 1, 'train/loss': 0.40396323800086975, 'train/accuracy': 81.25}\n",
            "{'epoch': 3, 'batch': 501, 'train/loss': 0.4083224466579879, 'train/accuracy': 90.5439121756487}\n",
            "{'epoch': 3, 'batch': 1001, 'train/loss': 0.3990872358972138, 'train/accuracy': 91.12762237762237}\n",
            "{'epoch': 3, 'batch': 1501, 'train/loss': 0.3917753177035419, 'train/accuracy': 91.55979347101932}\n",
            "{'epoch': 3, 'validation/loss': 0.4279682294836322, 'validation/accuracy': 85.80097087378641}\n",
            "Accuracy score improved from 85.2549 -> 85.801. Saving model... DONE!\n",
            "{'epoch': 4, 'batch': 1, 'train/loss': 0.30273306369781494, 'train/accuracy': 93.75}\n",
            "{'epoch': 4, 'batch': 501, 'train/loss': 0.3558875131095479, 'train/accuracy': 93.62524950099801}\n",
            "{'epoch': 4, 'batch': 1001, 'train/loss': 0.34843402139314045, 'train/accuracy': 93.96228771228772}\n",
            "{'epoch': 4, 'batch': 1501, 'train/loss': 0.3446843144617265, 'train/accuracy': 94.24550299800133}\n",
            "{'epoch': 4, 'validation/loss': 0.4780287579135987, 'validation/accuracy': 85.37621359223301}\n"
          ]
        }
      ],
      "source": [
        "def train():\n",
        "  vocab_size = len(roberta_tokenizer) # 50265 + 2\n",
        "\n",
        "  model = RoBERTaWithMLP(roberta_model,\n",
        "                            vocab_size,\n",
        "                            EMBEDDINGS_SIZE,\n",
        "                            config[\"hidden_layer_size\"]\n",
        "                            ).to(DEVICE)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "  # total_steps = len(train_loader) * EPOCHS\n",
        "  # scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "  #                                             num_warmup_steps = 0, # Default value in run_glue.py\n",
        "  #                                             num_training_steps = total_steps)\n",
        "  criterion = BCELoss()\n",
        "  best_acc = 0\n",
        "\n",
        "  for epoch in range(config[\"epochs\"]):\n",
        "    model.train()\n",
        "\n",
        "    loss, acc, f1, prec, rec = (0,) * 5\n",
        "\n",
        "    for i, (train_x, train_y, mask) in enumerate(train_loader):\n",
        "      # Move data to the device in use\n",
        "      train_x = train_x.to(DEVICE)\n",
        "      train_y = train_y.to(DEVICE)\n",
        "      mask = mask.to(DEVICE)\n",
        "\n",
        "      # Forward pass\n",
        "      output = model.forward(train_x, mask)\n",
        "      output = torch.reshape(output, (-1,))\n",
        "\n",
        "      smoothed_labels = smooth_labels(train_y, config['label_smoothing'])\n",
        "      curr_loss = criterion(output, smoothed_labels)\n",
        "\n",
        "      # Backward pass\n",
        "      optimizer.zero_grad()\n",
        "      curr_loss.backward()\n",
        "\n",
        "      # Parameters update\n",
        "      optimizer.step()\n",
        "      #scheduler.step()\n",
        "\n",
        "      # Performance evaluation\n",
        "      pred = torch.tensor([0 if x < 0.5 else 1 for x in output])\n",
        "      curr_acc = accuracy_score(train_y.cpu(), pred.cpu()) * 100.0\n",
        "      # curr_f1 = f1_score(train_y.cpu(), pred.cpu()) * 100.0\n",
        "      # curr_prec = precision_score(train_y.cpu(), pred.cpu()) * 100.0\n",
        "      # curr_rec = recall_score(train_y.cpu(), pred.cpu()) * 100.0\n",
        "\n",
        "      loss += float(curr_loss.item())\n",
        "      acc += float(curr_acc)\n",
        "      # f1 += curr_f1\n",
        "      # prec += curr_prec\n",
        "      # rec += curr_rec\n",
        "      \n",
        "      if (i%500==0):\n",
        "        print({\"epoch\": epoch + 1,\n",
        "                \"batch\": i + 1,\n",
        "                \"train/loss\": loss/(i+1),\n",
        "                \"train/accuracy\": acc/(i+1),\n",
        "                #  \"train/F1-score\": f1/(i+1),\n",
        "                #  \"train/precision\": prec/(i+1),\n",
        "                #  \"train/recall\": rec/(i+1)\n",
        "                })\n",
        "\n",
        "    model.eval()\n",
        "    loss, acc = evaluate(model, criterion)\n",
        "\n",
        "    print({\"epoch\": epoch + 1,\n",
        "              \"validation/loss\": loss,\n",
        "              \"validation/accuracy\": acc,\n",
        "              #  \"validation/F1-score\": f1,\n",
        "              #  \"validation/precision\": prec,\n",
        "              #  \"validation/recall\": rec\n",
        "              })\n",
        "\n",
        "    if acc > best_acc:\n",
        "      print(f\"Accuracy score improved from {round(best_acc, 4)} -> {round(acc, 4)}. Saving model...\", end=\"\")\n",
        "      best_acc = acc\n",
        "      torch.save(model, \"./model.pt\")\n",
        "      print(\" DONE!\")\n",
        "  \n",
        "  return model\n",
        "\n",
        "trained_model = train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pV8KSEDCVb2T"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M3hdt_aX_Xd"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hPEft3iMX-eU"
      },
      "outputs": [],
      "source": [
        "model = torch.load('./model.pt', map_location=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7v3DOGxQX95d"
      },
      "outputs": [],
      "source": [
        "def get_test_predictions(model):\n",
        "  model.eval()\n",
        "\n",
        "  truth = []\n",
        "  predictions=[]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for (test_x, test_y, mask) in test_loader:\n",
        "      # Move data to the device in use\n",
        "      test_x = test_x.to(DEVICE)\n",
        "      test_y = test_y.to(DEVICE)\n",
        "      mask = mask.to(DEVICE)\n",
        "\n",
        "      # Forward pass\n",
        "      output = model.forward(test_x, mask)\n",
        "      output = torch.reshape(output, (-1,))\n",
        "\n",
        "      # Model predictions\n",
        "      truth.extend(torch.flatten(test_y).tolist())\n",
        "      predictions.extend(torch.flatten(output, 0).tolist())\n",
        "\n",
        "  return truth, predictions\n",
        "\n",
        "truth, predictions = get_test_predictions(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTtCH9UEi8lM"
      },
      "source": [
        "## Use ROC curve to determine the classification threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qkTKA8ayhyGY"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, RocCurveDisplay, ConfusionMatrixDisplay\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(truth, predictions, pos_label=1)\n",
        "\n",
        "RocCurveDisplay.from_predictions(truth, predictions)  # NEW\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XWQ9mZW4ideP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST RESULTS:\n",
            "Accuracy: 87.0%\n",
            "Precision: 79.0%\n",
            "Recall: 81.0%\n",
            "F1: 80.0%\n"
          ]
        }
      ],
      "source": [
        "OPT_THRESHOLD = 0.6\n",
        "results = [1 if x > OPT_THRESHOLD else 0 for x in predictions]\n",
        "\n",
        "test_acc = accuracy_score(truth, results)\n",
        "test_rec = recall_score(truth, results)\n",
        "test_prec = precision_score(truth, results)\n",
        "test_f1 = f1_score(truth, results)\n",
        "\n",
        "print(\"TEST RESULTS:\")\n",
        "print(f\"Accuracy: {100*round(test_acc, 2)}%\")\n",
        "print(f\"Precision: {100*round(test_prec, 2)}%\")\n",
        "print(f\"Recall: {100*round(test_rec, 2)}%\")\n",
        "print(f\"F1: {100*round(test_f1, 2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3X03V9nYk-_T"
      },
      "outputs": [],
      "source": [
        "def predict(sentence):\n",
        "  encodings = roberta_tokenizer(sentence, add_special_tokens=True,\n",
        "                          padding=\"longest\", truncation=\"longest_first\",\n",
        "                          return_attention_mask=True, return_tensors=\"pt\")\n",
        "  \n",
        "  X = encodings['input_ids'].to(dtype=torch.int32, device=DEVICE)\n",
        "  mask = encodings['attention_mask'].to(dtype=torch.uint8, device=DEVICE)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    score = model.forward(X, mask).item()\n",
        "  return score, 1 if score > OPT_THRESHOLD else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dObHYIvMUwMy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.10426387935876846, 0)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"She concluded that, if her earlier results relating the quantity of uranium to its activity were correct, then these two minerals must contain small quantities of another substance that was far more active than uranium.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "poMPHgPEWNxK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9136044383049011, 1)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"In engineering, a computer is a complex electronic device capable of executing algorithms.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ujUKM4gpWrJF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9269786477088928, 1)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Radioactive decay (also known as nuclear decay, radioactivity, radioactive disintegration, or nuclear disintegration) is the process by which an unstable atomic nucleus loses energy by radiation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OR-wrCEdYjH7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9196864366531372, 1)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Dogs are animals that have four legs and are playful.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VcqVWMPQZ5Dw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.12848816812038422, 0)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Yellow, blue, green and red are colors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbmWYpIYmoWA"
      },
      "source": [
        "The following test definitions are taken from https://www.ucfmapper.com/education/various-types-definitions/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQZ53pTQmt7f"
      },
      "source": [
        "**Intensional definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pInd8NENmaZw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9284198880195618, 1)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Baked Goods are foods that are cooked in an oven of some fashion that uses prolonged dry heat, usually based on flour or corn.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoAfahkhmxts"
      },
      "source": [
        "**Extensional definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5L7S-Nv7miJs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9290803670883179, 1)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Baked Goods are breads, cakes, pastries, cookies, biscuits, scones and similar items of food that are cooked in an oven of some fashion.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IP5ypt8m0ba"
      },
      "source": [
        "**Stipulative definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ANI8lXo9m7zD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9243605732917786, 1)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Charlotte’s Sprinkle Scone is a baked vanilla flavored scone, dusted with sugar, covered in chocolate sprinkles both baked in and rolled onto the top of the scone.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynYWekZUnIhY"
      },
      "source": [
        "**Lexical definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "jB-LwFo2m90u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8273632526397705, 1)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Charlotte’s Sprinkle Scone: these wonderful scones are made with N parts flour, N parts water, N parts yeast, N eggs, N chocolate nibs, etc.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1AqPyjot2Y"
      },
      "source": [
        "**Partitive definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "a72yUwc4owgK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8927600979804993, 1)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"yeast: as a key ingredient for most baked goods that is commonly used as a leavening agent in baking bread and bakery products.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZKsmA9Oo6Oy"
      },
      "source": [
        "**Functional definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "QzaFspKuo83r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9158445000648499, 1)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"yeast: an ingredient that is commonly used as a leavening agent in baking bread and bakery products.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NH4PJbvoIE7"
      },
      "source": [
        "**Encyclopedic definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DIkC1Hs0oItS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9012754559516907, 1)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"yeast: as a key ingredient for most baked goods that is commonly used as a leavening agent in baking bread and bakery products, where it converts the fermentable sugars present in the dough’s gluten into carbon dioxide and ethanol, thus trapping the releasing bubbles of gas into the gluten and making the dough fill up like a balloon as it rises.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrklnIKGpXbA"
      },
      "source": [
        "**Theoretical definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "f69eDCsUpYzW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.6225274205207825, 1)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"A scone in America is a derivative of the British scone with the following differences that have occurred because of time and mannerisms. The American scone has twice the butter-to-flour ratio as the British Scone. It is also normally chock-full of little-bits of lovely, such as currants, chocolate nibs, etc. This has occurred because of the incorrigible need for inclusiveness in the American persona. They tend to blend everything and include everything in everything. It seems more is better applies not just to their life, but to their baking world as well.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roYi5KnoqYqi"
      },
      "source": [
        "**Synonym definition:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "E3CvfvzVqaPR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.5384039878845215, 0)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Biscuit: British version of an American Cookie.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uERRbKGxzCDD",
        "f3QP2FqI4RxL"
      ],
      "name": "TL_SimonePersiani.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "2fab139eab8d276e062bfdde454fcd48b84ed6bf64c5efaf64b2109faa450613"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
